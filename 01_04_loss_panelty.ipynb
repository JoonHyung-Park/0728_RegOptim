{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Loss Panelty\n",
    "\n",
    "이번 실습에서는 Loss Panelty를 이용해 정규화하는 방법에 대해 알아보고자 합니다. 우선 대부분은 Early Stop 실습과 동일하게 진행해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed=seed)\n",
    "tf.random.set_random_seed(seed)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape([-1, 28 * 28])\n",
    "x_test = x_test.reshape([-1, 28 * 28])\n",
    "\n",
    "m = np.random.randint(0, high=60000, size=1100, dtype=np.int64)\n",
    "x_train = x_train[m]\n",
    "y_train = y_train[m]\n",
    "\n",
    "i = np.arange(1100)\n",
    "np.random.shuffle(i)\n",
    "x_train = x_train[i]\n",
    "y_train = y_train[i]\n",
    "\n",
    "x_valid = x_train[:100]\n",
    "y_valid = y_train[:100]\n",
    "\n",
    "x_train = x_train[100:]\n",
    "y_train = y_train[100:]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 28 * 28])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "n_units = [28 * 28, 512, 512, 10]\n",
    "\n",
    "weights, biases = [], []\n",
    "for i, (n_in, n_out) in enumerate(zip(n_units[:-1], n_units[1:])):\n",
    "    stddev = math.sqrt(2 / n_in) # Kaiming He Initialization\n",
    "    weight = tf.Variable(tf.random.truncated_normal([n_in, n_out], mean=0, stddev=stddev))\n",
    "    bias = tf.Variable(tf.zeros([n_out]))\n",
    "    weights.append(weight)\n",
    "    biases.append(bias)\n",
    "    \n",
    "layer = x \n",
    "for i, (weight, bias) in enumerate(zip(weights, biases)):\n",
    "    layer = tf.matmul(layer, weight) + bias\n",
    "    if i < len(weights) - 1:\n",
    "        layer = tf.nn.tanh(layer)        \n",
    "y_hat = layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Panelty를 이용한 정규화는 loss 함수를 변화시킴으로써 정규화 효과를 얻는 방식을 말합니다. 우리는 이번 실습에서 가장 자주 쓰이는 loss panelty 중 하나인 L2 panelty(weight decay)를 사용해보고자 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hot = tf.one_hot(y, 10)\n",
    "costs = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        labels=y_hot, logits=y_hat)\n",
    "cross_entropy_loss = tf.reduce_mean(costs)\n",
    "regularization_loss = tf.add_n([tf.reduce_sum(tf.square(w)) for w in weights])\n",
    "loss = cross_entropy_loss + 0.001 * regularization_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 다른 부분들은 이전 실습과 동일하게 진행해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.6889 2.0048 1.9541 0.9550 0.8200 0.8492\n",
      "20 1.4178 1.8514 1.7703 0.9960 0.8800 0.8745\n",
      "30 1.2858 1.7532 1.6579 1.0000 0.8900 0.8802\n",
      "40 1.1844 1.6616 1.5609 1.0000 0.8900 0.8840\n",
      "50 1.0942 1.5726 1.4739 1.0000 0.8800 0.8841\n",
      "60 1.0126 1.4846 1.3936 1.0000 0.8900 0.8844\n",
      "70 0.9383 1.4027 1.3199 1.0000 0.9000 0.8855\n",
      "80 0.8704 1.3362 1.2519 1.0000 0.9000 0.8852\n",
      "90 0.8083 1.2797 1.1900 1.0000 0.9000 0.8841\n",
      "100 0.7514 1.2228 1.1337 1.0000 0.8900 0.8832\n",
      "110 0.6991 1.1749 1.0822 1.0000 0.9000 0.8828\n",
      "120 0.6511 1.1317 1.0333 1.0000 0.9000 0.8831\n",
      "130 0.6070 1.0868 0.9885 1.0000 0.9000 0.8824\n",
      "140 0.5664 1.0466 0.9472 1.0000 0.9000 0.8825\n",
      "150 0.5292 1.0066 0.9095 1.0000 0.8900 0.8827\n",
      "160 0.4950 0.9699 0.8750 1.0000 0.8800 0.8819\n",
      "170 0.4636 0.9346 0.8438 1.0000 0.9000 0.8813\n",
      "0.8855\n"
     ]
    }
   ],
   "source": [
    "accuracy = tf.count_nonzero(\n",
    "        tf.cast(tf.equal(tf.argmax(y_hot, 1), tf.argmax(y_hat, 1)),\n",
    "                tf.int64)) / tf.cast(tf.shape(y_hot)[0], tf.int64)\n",
    "\n",
    "extra_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "gpu_options = tf.GPUOptions()\n",
    "gpu_options.allow_growth = True\n",
    "session = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "max_valid_epoch_idx = 0\n",
    "max_valid_accuracy = 0.0\n",
    "final_test_accuracy = 0.0\n",
    "weight_values = []\n",
    "for epoch_idx in range(1, 1000 + 1):\n",
    "    session.run(\n",
    "            train_op,\n",
    "            feed_dict={\n",
    "                x: x_train,\n",
    "                y: y_train\n",
    "            })\n",
    "    \n",
    "    if epoch_idx % 10 == 0:\n",
    "        train_loss_value, train_accuracy_value = session.run(\n",
    "            [loss, accuracy],\n",
    "            feed_dict={\n",
    "                x: x_train,\n",
    "                y: y_train\n",
    "            })\n",
    "        \n",
    "        valid_loss_value, valid_accuracy_value = session.run(\n",
    "            [loss, accuracy],\n",
    "            feed_dict={\n",
    "                x: x_valid,\n",
    "                y: y_valid\n",
    "            })\n",
    "            \n",
    "        test_loss_value, test_accuracy_value = session.run(\n",
    "            [loss, accuracy],\n",
    "            feed_dict={\n",
    "                x: x_test,\n",
    "                y: y_test\n",
    "            })\n",
    "\n",
    "        print(epoch_idx, '%.4f' % train_loss_value, '%.4f' % valid_loss_value, '%.4f' % test_loss_value, '%.4f' % train_accuracy_value, '%.4f' % valid_accuracy_value, '%.4f' % test_accuracy_value)\n",
    "        \n",
    "        if max_valid_accuracy < valid_accuracy_value:\n",
    "            max_valid_accuracy = valid_accuracy_value \n",
    "            max_valid_epoch_idx = epoch_idx\n",
    "            final_test_accuracy = test_accuracy_value\n",
    "            \n",
    "            weight_values = session.run(weights)\n",
    "            \n",
    "    # Early Stop\n",
    "    if max_valid_epoch_idx + 100 < epoch_idx:\n",
    "        break\n",
    "        \n",
    "print(final_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "88.05% -> 88.55% 로 성능이 0.5% 향상한 것을 확인할 수 있었습니다.\n",
    "\n",
    "이제 최종 모델 파라미터의 각 element의 distribution을 확인해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = np.concatenate([w.flatten() for w in weight_values], axis=None)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(dist, bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1과 L2를 동시에 사용하는 정규화 panelty term을 디자인할 수도 있을 것입니다. L1이나 L2를 사용할 때, 각 weight matrix 별로 다른 람다값을 사용하면 더 좋은 성능을 가진 네트워크를 가질 수 있지만, 찾아야 하는 파라미터가 너무 많아져 practical하지 않습니다. \n",
    "\n",
    "### 연습 문제\n",
    "\n",
    "Q1. 람다 값을 변경해보면서 test accuracy 와 weight distribution의 변화를 확인해보세요. \n",
    "\n",
    "Q2. L2정규화를 L1으로 바꿔보고, L1에 맞는 람다 값을 찾아보세요. 정규화를 이용해서 성능을 향상시킬 수 있는지, weight distribution에는 어떤 변화가 있는지 확인해봅시다.\n",
    "(힌트는 [여기](01_04_loss_panelty_Q2_hint.txt)에서 확인하실 수 있습니다.)\n",
    "(정답은 [여기](01_04_loss_panelty_Q2_answer.txt)에서 확인하실 수 있습니다.)\n",
    "\n",
    "Q3. (도전과제) L1 정규화를 이용해 각 hidden layer의 적정 hidden unit 갯수를 찾아봅시다. \n",
    "\n",
    "주의사항! 코드를 수정한 이후에는 Kernel > Restart & Run All 을 통해 네트워크를 처음부터 다시 학습시켜 주세요. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 실습\n",
    "\n",
    "다음 [실습](01_05_hidden_layer_stabilization.ipynb)에서는 Hidden Layer의 statistics을 안정화시키는 방식에 대해서 배워보고자 합니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
